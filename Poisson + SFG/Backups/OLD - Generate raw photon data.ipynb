{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92cd374",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33681fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/users/ids29/DGRB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8accada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aegis\n",
    "import numpy as np\n",
    "import torch\n",
    "import healpy as hp\n",
    "import pickle as pk\n",
    "from astropy import units\n",
    "from astropy import constants as c\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import os\n",
    "from sbi.inference import SNLE, SNPE#, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "# from sbi.inference.base import infer\n",
    "from getdist import plots, MCSamples\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from scipy.integrate import quad, simpson\n",
    "import pickle\n",
    "from scipy.stats import norm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f04ab14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grains=1000\n",
    "num_simulations = 336\n",
    "num_workers = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1534fabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_range_aegis = [[], []]\n",
    "abundance_luminosity_and_spectrum_list = []\n",
    "source_class_list = []\n",
    "parameter_names = []\n",
    "energy_range = [1000, 100000] #MeV \n",
    "energy_range_gen = [energy_range[0]*0.5, energy_range[1]*18]\n",
    "max_radius = 8.5 + 20*2 #kpc\n",
    "exposure = 2000*10*0.2 #cm^2 yr\n",
    "flux_cut = 1e-9 #photons/cm^2/s\n",
    "angular_cut = np.pi #10*u.deg.to('rad') #degrees\n",
    "angular_cut_gen = np.pi #angular_cut*1.5\n",
    "lat_cut = 0 #2*u.deg.to('rad') #degrees\n",
    "lat_cut_gen = lat_cut*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d4064bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cosmology = 'Planck18'\n",
    "z_range = [0, 14]\n",
    "luminosity_range = 10.0**np.array([37, 50]) # Minimum value set by considering Andromeda distance using Fermi as benchmark and receiving 0.1 photon at detector side\n",
    "my_AEGIS = aegis.aegis(abundance_luminosity_and_spectrum_list, source_class_list, parameter_range_aegis, energy_range, luminosity_range, max_radius, exposure, angular_cut, lat_cut, flux_cut, energy_range_gen=energy_range_gen, cosmology = my_cosmology, z_range = z_range, verbose = False)\n",
    "my_AEGIS.angular_cut_gen, my_AEGIS.lat_cut_gen = angular_cut_gen, lat_cut_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d2cb393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_poisson(energy, params):\n",
    "\n",
    "    Phi_Poisson =  params[0] \n",
    "    \n",
    "    Gamma = 2.2\n",
    "    Emin, Emax = energy_range[0], energy_range[1]\n",
    "    exposure_det = exposure*units.yr.to('s') # cm^2 s\n",
    "    expected_photons = 772_340 # Value such that it produces the twice number of photons (after mock_observe is applied) as detected by Fermi-LAT, under the condition that Phi_Poisson = 2\n",
    "    num_photons_exposure_solidAngle = expected_photons / exposure_det / (4*np.pi) # photons/cm^2/sec/sr\n",
    "    normalization =  (Emax**(1-Gamma) - Emin**(1-Gamma)) / (1-Gamma) \n",
    "    prop_const = num_photons_exposure_solidAngle / normalization\n",
    "    return Phi_Poisson * prop_const * energy**(-Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28f2cc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma_SFG = 2.2\n",
    "gamma_energy_bounds = energy_range_gen  # in MeV\n",
    "E_photon_GeV_SFG = ((-Gamma_SFG + 1) / (-Gamma_SFG + 2) *\n",
    "                (gamma_energy_bounds[1]**(-Gamma_SFG + 2) - gamma_energy_bounds[0]**(-Gamma_SFG + 2)) /\n",
    "                (gamma_energy_bounds[1]**(-Gamma_SFG + 1) - gamma_energy_bounds[0]**(-Gamma_SFG + 1))) # in MeV\n",
    "E_photon_SFG = E_photon_GeV_SFG * 1.60218e-6  # erg\n",
    "\n",
    "res = int(1e4)\n",
    "log_LIRs = np.linspace(-5, 25, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc38e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZL_SFG1(z, l, params):\n",
    "\n",
    "\n",
    "    Phi_star = params[1]\n",
    "\n",
    "    l_erg = l * E_photon_SFG # erg/s\n",
    "    LFs = np.zeros_like(l)\n",
    "\n",
    "    def Phi_IR(log_LIR): #log_LIR = log_10(L_IR / solar_luminosity) # unitless\n",
    "\n",
    "        # from Table 8 in Gruppioni et al.\n",
    "        # Phi_star = 10**(-2.08) # Mpc^{-3} dex^{-1}\n",
    "        Lstar = 10**(9.46) # Solar luminosity\n",
    "        alpha = 1.00\n",
    "        sigma = 0.50\n",
    "\n",
    "        LIR = 10**log_LIR # solar luminosity\n",
    "\n",
    "        Phi_IR = Phi_star * (LIR / Lstar)**(1 - alpha) * np.exp(-1 / (2 * sigma**2) * (np.log10(1 + LIR / Lstar))**2) # from Gruppioni paper eqn (3)  \t\n",
    "\n",
    "        return Phi_IR\n",
    "\n",
    "    def PDF_log_Lgamma_given_log_LIR(log_LIR, log_Lgamma): #log_LIR = log_10(L_IR / solar_luminosity) # unitless\n",
    "        LIR_solar_luminosity = 10**log_LIR # Solar luminosity\n",
    "        L_IR_erg_second = LIR_solar_luminosity * 3.826e33 # erg/s\n",
    "\n",
    "        a = 1.09\n",
    "        g = 40.8\n",
    "        sigma_SF = 0.202 \n",
    "\n",
    "        mean = g + a * np.log10(L_IR_erg_second / 1e45)\n",
    "        std = sigma_SF\n",
    "\n",
    "        return norm.pdf(log_Lgamma, loc=mean, scale=std)\n",
    "\n",
    "    def integrand(PhiIR_of_logLIRs, log_LIRs, log_Lgamma):\n",
    "        return PhiIR_of_logLIRs * PDF_log_Lgamma_given_log_LIR(log_LIRs, log_Lgamma)\n",
    "\n",
    "    PhiIR_of_logLIRs = Phi_IR(log_LIRs)\n",
    "\n",
    "    for i in range(LFs.shape[0]):\n",
    "        for j in range(LFs.shape[1]):\n",
    "            LFs[i,j] = simpson(integrand(PhiIR_of_logLIRs, log_LIRs, np.log10(l_erg[i,j])), x=log_LIRs)\n",
    "    return 1e-9 / np.log(10) / l * LFs # LF has spatial units of Mpc^{-3}. We need to convert this to kpc^{-3}. Hence the factor of 1e-9\n",
    "\n",
    "\n",
    "def spec_SFG1(energy, params):\n",
    "    Gamma = 2.2\n",
    "    return energy**(-Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a7790a",
   "metadata": {},
   "outputs": [],
   "source": [
    "als_Poisson = [spec_poisson]\n",
    "als_SFG1 = [ZL_SFG1, spec_SFG1]\n",
    "my_AEGIS.abun_lum_spec = [als_Poisson, als_SFG1]\n",
    "my_AEGIS.source_class_list = ['isotropic_diffuse', 'extragalactic_isotropic_faint_single_spectrum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eefb8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple simulator with the total number of photons as the summary statistic\n",
    "def simulator(params):\n",
    "\n",
    "    input_params = params.numpy()\n",
    "\n",
    "    source_info = my_AEGIS.create_sources(input_params, grains=grains, epsilon=1e-2)\n",
    "    photon_info = my_AEGIS.generate_photons_from_sources(input_params, source_info, grains=grains) \n",
    "    obs_info = {'psf_fits_path': '/home/users/ids29/DGRB/FERMI_files/psf_P8R3_ULTRACLEANVETO_V2_PSF.fits', 'edisp_fits_path': '/home/users/ids29/DGRB/FERMI_files/edisp_P8R3_ULTRACLEANVETO_V2_PSF.fits', 'event_type': 'PSF3', 'exposure_map': None}\n",
    "    obs_photon_info = my_AEGIS.mock_observe(photon_info, obs_info)\n",
    "    \n",
    "    return obs_photon_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_simulate_for_sbi(proposal, num_simulations=1000, num_workers=32):\n",
    "    \"\"\"\n",
    "    Simulates the model in parallel using joblib.\n",
    "    Each simulation call samples a parameter from the proposal and passes the index to the simulator.\n",
    "    \"\"\"\n",
    "    def run_simulation(i):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"i= {i}\")\n",
    "        # Sample a parameter from the proposal (sbi.utils.BoxUniform has a .sample() method)\n",
    "        theta_i = proposal.sample()\n",
    "        photon_info = simulator(theta_i)\n",
    "        return theta_i, photon_info\n",
    "\n",
    "    # Run simulations in parallel using joblib.\n",
    "    # Switch to the threading backend\n",
    "    with parallel_backend('threading', n_jobs=num_workers):\n",
    "        results = Parallel(verbose=5, timeout=None)(delayed(run_simulation)(i) for i in range(num_simulations))\n",
    "\n",
    "    # results = Parallel(n_jobs=num_workers, timeout=None)(delayed(run_simulation)(i) for i in range(num_simulations))\n",
    "    theta_list, photon_info_list = zip(*results)\n",
    "\n",
    "    theta_tensor = torch.stack(theta_list, dim=0).to(torch.float32)\n",
    "    \n",
    "    \n",
    "    return theta_tensor, photon_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508cf1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend ThreadingBackend with 48 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 20\n",
      "i= 10\n",
      "i= 30\n",
      "i= 40\n",
      "i= 0\n",
      "i= 50\n",
      "i= 60\n",
      "i= 70\n",
      "i= 80\n",
      "i= 90\n",
      "i= 100\n",
      "i= 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done  66 tasks      | elapsed: 832.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 120\n",
      "i= 130\n",
      "i= 140\n",
      "i= 150\n",
      "i= 160\n",
      "i= 170\n",
      "i= 180\n",
      "i= 190\n",
      "i= 200\n",
      "i= 210\n",
      "i= 220\n",
      "i= 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Done 192 tasks      | elapsed: 1766.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 240\n",
      "i= 250\n",
      "i= 260\n",
      "i= 270\n",
      "i= 280\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      5\u001b[39m prior_range = torch.tensor([[Phi_Poisson_training_range[\u001b[32m0\u001b[39m], Phi_SFG_training_range[\u001b[32m0\u001b[39m]],\n\u001b[32m      6\u001b[39m                             [Phi_Poisson_training_range[\u001b[32m1\u001b[39m], Phi_SFG_training_range[\u001b[32m1\u001b[39m]]])\n\u001b[32m      8\u001b[39m prior = utils.BoxUniform(low=prior_range[\u001b[32m0\u001b[39m], high=prior_range[\u001b[32m1\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m train_thetas, train_photon_info = manual_simulate_for_sbi(prior,\n\u001b[32m     11\u001b[39m                                    num_simulations=num_simulations,\n\u001b[32m     12\u001b[39m                                    num_workers=num_workers)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mmanual_simulate_for_sbi\u001b[39m\u001b[34m(proposal, num_simulations, num_workers)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Run simulations in parallel using joblib.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Switch to the threading backend\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[33m'\u001b[39m\u001b[33mthreading\u001b[39m\u001b[33m'\u001b[39m, n_jobs=num_workers):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     results = Parallel(verbose=\u001b[32m5\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m)(delayed(run_simulation)(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_simulations))\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# results = Parallel(n_jobs=num_workers, timeout=None)(delayed(run_simulation)(i) for i in range(num_simulations))\u001b[39;00m\n\u001b[32m     20\u001b[39m theta_list, photon_info_list = \u001b[38;5;28mzip\u001b[39m(*results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sbi_env/lib/python3.13/site-packages/joblib/parallel.py:2071\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2065\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2071\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sbi_env/lib/python3.13/site-packages/joblib/parallel.py:1681\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1678\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1680\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1681\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1683\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1684\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/sbi_env/lib/python3.13/site-packages/joblib/parallel.py:1799\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1789\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1794\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1797\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1798\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1799\u001b[39m         time.sleep(\u001b[32m0.01\u001b[39m)\n\u001b[32m   1800\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1802\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1803\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1810\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Define the prior using sbi.utils.BoxUniform\n",
    "Phi_Poisson_training_range = [0, 0.184]\n",
    "Phi_SFG_training_range = [0, 2]\n",
    "\n",
    "prior_range = torch.tensor([[Phi_Poisson_training_range[0], Phi_SFG_training_range[0]],\n",
    "                            [Phi_Poisson_training_range[1], Phi_SFG_training_range[1]]])\n",
    "\n",
    "prior = utils.BoxUniform(low=prior_range[0], high=prior_range[1])\n",
    "\n",
    "train_thetas, train_photon_info = manual_simulate_for_sbi(prior,\n",
    "                                   num_simulations=num_simulations,\n",
    "                                   num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a11414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'photon_info_list' is a list of dictionaries\n",
    "\n",
    "# Save to file\n",
    "with open('train_data_Poisson_SFG_kerr_336.pkl', 'wb') as f:\n",
    "    pickle.dump(train_photon_info, f)\n",
    "\n",
    "# Save to file\n",
    "torch.save(train_thetas, 'train_thetas_Poisson_SFG_kerr_336.pt')\n",
    "torch.save(prior_range, 'prior_range_Poisson_SFG_kerr_336.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba6065",
   "metadata": {},
   "source": [
    "Test case 1: only Poisson contirbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa771c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Phis_1 = [1, 0] # [Phi_Poisson, Phi_SFG]\n",
    "# test_theta_1 = torch.tensor([test_Phis_1[0], test_Phis_1[1]]) # A_Poisson = 1\n",
    "# test_photon_info_1 = simulator(test_theta_1)\n",
    "# print(f\"Poisson-only case: Number of photons after mock_observe: {test_photon_info_1['energies'].size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ce95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(test_theta_1, r'test_theta_Poisson_only.pt')\n",
    "\n",
    "# with open(r'test_data_Poisson_only.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_photon_info_1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8780d9",
   "metadata": {},
   "source": [
    "Test case 2: only SFG contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc658c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFG only case: Number of photons after mock_observe: 32390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ids29/DGRB/aegis.py:558: RuntimeWarning: invalid value encountered in divide\n",
      "  Es = energy_vals[self.draw_from_pdf(energy_vals, spectrum/np.sum(spectrum), num_photons)]\n"
     ]
    }
   ],
   "source": [
    "# test_Phis_2 = [0, 10**(-2.08)] # [Phi_Poisson, Phi_SFG]\n",
    "# test_theta_2 = torch.tensor([test_Phis_2[0], test_Phis_2[1]]) # A_Poisson = 1\n",
    "# test_photon_info_2 = simulator(test_theta_2)\n",
    "# print(f\"SFG only case: Number of photons after mock_observe: {test_photon_info_2['energies'].size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a655ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(test_theta_2, r'test_theta_SFG_only.pt')\n",
    "\n",
    "# with open(r'test_data_SFG_only.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_photon_info_2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c835db25",
   "metadata": {},
   "source": [
    "Test case 3: SFG + Poisson - 50% + 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06c8554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisson + SFG case: Number of photons after mock_observe: 32138\n"
     ]
    }
   ],
   "source": [
    "# test_Phis_3 = [1/2, 10**(-2.08)/2] # [Phi_Poisson, Phi_SFG]\n",
    "# test_theta_3 = torch.tensor([get_theta(test_Phis_3[0]), get_theta(test_Phis_3[1])]) # A_Poisson = 1\n",
    "# test_photon_info_3 = simulator(test_theta_3)\n",
    "# print(f\"Poisson + SFG case: Number of photons after mock_observe: {test_photon_info_3['energies'].size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d054ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(test_theta_3, r'test_theta_Poisson_SFG.pt')\n",
    "\n",
    "# with open(r'test_data_Poisson_SFG.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_photon_info_3, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f17e38",
   "metadata": {},
   "source": [
    "Generate a test case withthe max theta values to decide the value of N_side for the counts-only histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49faae80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisson + SFG case: Number of photons after mock_observe: 7795317\n"
     ]
    }
   ],
   "source": [
    "# test_theta_4 = torch.tensor([Phi_Poisson_training_range[1], Phi_SFG_training_range[1]]) # [Phi_Poisson, Phi_SFG]\n",
    "# test_photon_info_4 = simulator(test_theta_4)\n",
    "# print(f\"Poisson + SFG case: Number of photons after mock_observe: {test_photon_info_4['energies'].size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2896109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(test_theta_4, r'max_theta_Poisson_SFG.pt')\n",
    "\n",
    "# with open(r'max_data_Poisson_SFG_max_thetas.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_photon_info_4, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1d8ca5",
   "metadata": {},
   "source": [
    "Find Phi_SFG in SFG-only case such that you get 2 times the Fermi-LAT number of photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de1c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phis_SFG_try = np.linspace(0.05, 0.2, 48)\n",
    "\n",
    "# # the function that does one “i”-th iteration\n",
    "# def count_photons(Phi_SFG):\n",
    "#     # make your 2-element tensor\n",
    "#     Phis = torch.tensor([0.0, Phi_SFG])\n",
    "#     # run the simulation\n",
    "#     photon_info = simulator(Phis)\n",
    "#     # return the number of photons\n",
    "#     # (you may need .size(0) or int(...) depending on what .size returns)\n",
    "#     return photon_info['energies'].size\n",
    "\n",
    "# # run in parallel on 48 processes\n",
    "# results = Parallel(n_jobs=48, verbose=5)(\n",
    "#     delayed(count_photons)(Phi_SFG)\n",
    "#     for Phi_SFG in Phis_SFG_try\n",
    "# )\n",
    "\n",
    "# # convert back into your array\n",
    "# num_photons = np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3d41c5",
   "metadata": {},
   "source": [
    "Adjust 'expected_photons' in the Posisson spectrum for Poisson-only case such that you get 2 times the Fermi-LAT number of photons. Here, I set Phi_Poisson = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d8aac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=48)]: Using backend LokyBackend with 48 concurrent workers.\n",
      "[Parallel(n_jobs=48)]: Done   3 out of  48 | elapsed:  9.2min remaining: 138.4min\n",
      "[Parallel(n_jobs=48)]: Done  13 out of  48 | elapsed: 11.4min remaining: 30.7min\n",
      "[Parallel(n_jobs=48)]: Done  23 out of  48 | elapsed: 13.4min remaining: 14.6min\n",
      "[Parallel(n_jobs=48)]: Done  33 out of  48 | elapsed: 14.4min remaining:  6.5min\n",
      "[Parallel(n_jobs=48)]: Done  43 out of  48 | elapsed: 16.1min remaining:  1.9min\n",
      "[Parallel(n_jobs=48)]: Done  48 out of  48 | elapsed: 17.2min finished\n"
     ]
    }
   ],
   "source": [
    "# parameters_try = np.linspace(500_000, 900_000, 48)\n",
    "\n",
    "# # 2. wrap one iteration in a function\n",
    "# def count_photons(parameter):\n",
    "#     # build the same 2‐element tensor\n",
    "#     parameters_sim = torch.tensor([parameter, 0])\n",
    "#     # run your simulator\n",
    "#     photon_info = simulator(parameters_sim)\n",
    "\n",
    "#     return photon_info['energies'].size\n",
    "\n",
    "# # 3. dispatch across 48 workers\n",
    "# num_photons = Parallel(n_jobs=num_workers, verbose=5)(\n",
    "#     delayed(count_photons)(param)\n",
    "#     for param in parameters_try\n",
    "# )\n",
    "\n",
    "# # 4. (optional) convert back to numpy array for any downstream work\n",
    "# num_photons = np.array(num_photons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6e3acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706450\n",
      "772340.4255319149\n"
     ]
    }
   ],
   "source": [
    "# print(num_photons[32])\n",
    "# print(parameters_try[32])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

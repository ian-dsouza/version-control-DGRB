{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25726408",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a95dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7138f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = \"bohr\"\n",
    "\n",
    "# Number of files\n",
    "num_files = 416\n",
    "# Base filename components\n",
    "base_name_data_BG = \"train_data_BG_\" + server\n",
    "base_name_data_DM = \"train_data_DM_\" + server\n",
    "ext_data = \".pkl\"\n",
    "\n",
    "base_name_thetas_BG = \"train_thetas_BG_\" + server\n",
    "base_name_thetas_DM = \"train_thetas_DM_\" + server\n",
    "ext_thetas = \".pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e34ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Prepare list to hold all dictionaries\n",
    "data_list = []\n",
    "thetas_list = []\n",
    "\n",
    "for i in range(num_files):\n",
    "    # Data files\n",
    "    # For background signal\n",
    "    filename_data_BG = f\"{base_name_data_BG}_{i}{ext_data}\"\n",
    "    if not os.path.exists(filename_data_BG):\n",
    "        raise FileNotFoundError(f\"Expected file not found: {filename_data_BG}\")\n",
    "    with open(filename_data_BG, \"rb\") as f:\n",
    "        data_BG = pickle.load(f)  # Unpickle the dictionary\n",
    "    # For DM signal\n",
    "    filename_data_DM = f\"{base_name_data_DM}_{i}{ext_data}\"\n",
    "    if not os.path.exists(filename_data_DM):\n",
    "        raise FileNotFoundError(f\"Expected file not found: {filename_data_DM}\")\n",
    "    with open(filename_data_DM, \"rb\") as f:\n",
    "        data_DM = pickle.load(f)  # Unpickle the dictionary\n",
    "\n",
    "    combined_angles = np.concatenate((data_BG['angles'], data_DM['angles']), axis=0) # vetcical stack\n",
    "    combined_energies  = np.concatenate((data_BG['energies'], data_DM['energies']), axis=0) # vertical stack\n",
    "    data_1_sim = {\n",
    "    'angles': combined_angles,\n",
    "    'energies': combined_energies\n",
    "    }\n",
    "\n",
    "    data_list.append(data_1_sim)\n",
    "\n",
    "\n",
    "\n",
    "    # Theta files\n",
    "    # For background signal\n",
    "    filename_thetas_BG = f\"{base_name_thetas_BG}_{i}{ext_thetas}\"\n",
    "    if not os.path.exists(filename_thetas_BG):\n",
    "        raise FileNotFoundError(f\"Missing file: {filename_thetas_BG}\")\n",
    "    theta_BG = torch.load(filename_thetas_BG) \n",
    "    # Ensure it’s the expected shape\n",
    "    if theta_BG.ndim != 1 or theta_BG.numel() != 1:\n",
    "        raise ValueError(f\"Unexpected shape in {filename_thetas_BG}: {theta_BG.shape}\")\n",
    "    # For DM signal\n",
    "    filename_thetas_DM = f\"{base_name_thetas_DM}_{i}{ext_thetas}\"\n",
    "    if not os.path.exists(filename_thetas_DM):\n",
    "        raise FileNotFoundError(f\"Missing file: {filename_thetas_DM}\")\n",
    "    theta_DM = torch.load(filename_thetas_DM) \n",
    "    # Ensure it’s the expected shape\n",
    "    if theta_DM.ndim != 1 or theta_DM.numel() != 2:\n",
    "        raise ValueError(f\"Unexpected shape in {filename_thetas_DM}: {theta_DM.shape}\")\n",
    "    \n",
    "    thetas_1_sim = torch.cat((theta_BG, theta_DM), dim=0)\n",
    "    \n",
    "    thetas_list.append(thetas_1_sim)\n",
    "\n",
    "# Stack into a single (260, 2) tensor\n",
    "thetas_tensor = torch.stack(thetas_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd50c904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data_list): 416\n",
      "thetas_tensor.shape: torch.Size([416, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"len(data_list): {len(data_list)}\")\n",
    "print(f\"thetas_tensor.shape: {thetas_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77531d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 416 files and saved combined data to 'combined_train_data_bohr.pkl'.\n",
      "Saved combined thetas tensor of shape torch.Size([416, 3]) to 'combined_train_thetas_bohr.pt'.\n"
     ]
    }
   ],
   "source": [
    "# Save data\n",
    "output_file_data = \"combined_train_data_\" + server + \".pkl\"\n",
    "with open(output_file_data, \"wb\") as f:\n",
    "    pickle.dump(data_list, f)  # Serialize the list of dicts \n",
    "\n",
    "print(f\"Loaded {len(data_list)} files and saved combined data to '{output_file_data}'.\")\n",
    "\n",
    "# Save thetas\n",
    "output_file_thetas = \"combined_train_thetas_\" + server + \".pt\"\n",
    "torch.save(thetas_tensor, output_file_thetas)\n",
    "\n",
    "print(f\"Saved combined thetas tensor of shape {thetas_tensor.shape} to '{output_file_thetas}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

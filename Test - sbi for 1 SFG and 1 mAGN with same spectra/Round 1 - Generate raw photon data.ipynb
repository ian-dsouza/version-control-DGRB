{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Current working dir  …/DGRB Scripts/Test - sbi for 1 SFG and 1 mAGN…\n",
    "# parent[0] → …/DGRB Scripts\n",
    "# parent[1] → …/home/users/ids29           ← where “DGRB/” lives\n",
    "package_path = Path.cwd().parents[1] / \"DGRB\"   # /home/users/ids29/DGRB\n",
    "\n",
    "sys.path.insert(0, str(package_path))           # make it import-able\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aegis\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import torch\n",
    "import pickle as pk\n",
    "from astropy import units as u\n",
    "from astropy import constants as c\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import os\n",
    "from sbi.inference import SNLE, SNPE#, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "# from sbi.inference.base import infer\n",
    "from getdist import plots, MCSamples\n",
    "import pickle\n",
    "from scipy.stats import norm\n",
    "from scipy.integrate import quad, simpson\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grains=1000\n",
    "num_simulations = 1000\n",
    "num_workers = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_range = [[], []]\n",
    "abundance_luminosity_and_spectrum_list = []\n",
    "source_class_list = []\n",
    "parameter_names = []\n",
    "energy_range = [1000, 100000] #MeV\n",
    "energy_range_gen = [energy_range[0]*0.5, energy_range[1]*18]\n",
    "max_radius = 8.5 + 20*2 #kpc\n",
    "exposure = 2000*10*0.2 #cm^2 yr\n",
    "flux_cut = 1e-9 #photons/cm^2/s\n",
    "angular_cut = np.pi #10*u.deg.to('rad') #degrees\n",
    "angular_cut_gen = np.pi #angular_cut*1.5\n",
    "lat_cut = 0 #2*u.deg.to('rad') #degrees\n",
    "lat_cut_gen = lat_cut*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cosmology = 'Planck18'\n",
    "z_range = [0, 14]\n",
    "luminosity_range = 10.0**np.array([37, 50]) # Minimum value set by considering Andromeda distance using Fermi as benchmark and receiving 0.1 photon at detector side\n",
    "my_AEGIS = aegis.aegis(abundance_luminosity_and_spectrum_list, source_class_list, parameter_range, energy_range, luminosity_range, max_radius, exposure, angular_cut, lat_cut, flux_cut, energy_range_gen=energy_range_gen, cosmology = my_cosmology, z_range = z_range, verbose = False)\n",
    "my_AEGIS.angular_cut_gen, my_AEGIS.lat_cut_gen = angular_cut_gen, lat_cut_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma_SFG = 2.2\n",
    "gamma_energy_bounds = energy_range_gen  # in MeV\n",
    "E_photon_MeV_SFG = ((-Gamma_SFG + 1) / (-Gamma_SFG + 2) *\n",
    "                (gamma_energy_bounds[1]**(-Gamma_SFG + 2) - gamma_energy_bounds[0]**(-Gamma_SFG + 2)) /\n",
    "                (gamma_energy_bounds[1]**(-Gamma_SFG + 1) - gamma_energy_bounds[0]**(-Gamma_SFG + 1))) # in MeV\n",
    "E_photon_SFG = E_photon_MeV_SFG * 1.60218e-6  # erg\n",
    "\n",
    "Gamma_mAGN = 2.2 # enforced by user to match SFG spectrum (actually should 2.25)\n",
    "gamma_energy_bounds = energy_range_gen  # in MeV\n",
    "E_photon_MeV_mAGN = ((-Gamma_mAGN + 1) / (-Gamma_mAGN + 2) *\n",
    "                (gamma_energy_bounds[1]**(-Gamma_mAGN + 2) - gamma_energy_bounds[0]**(-Gamma_mAGN + 2)) /\n",
    "                (gamma_energy_bounds[1]**(-Gamma_mAGN + 1) - gamma_energy_bounds[0]**(-Gamma_mAGN + 1))) # MeV\n",
    "E_photon_mAGN = E_photon_MeV_mAGN * 1.60218e-6  # erg\n",
    "\n",
    "res = int(1e4)\n",
    "log_LIRs = np.linspace(-5, 25, res)\n",
    "log_L5Gs = np.linspace(20, 55, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZL_SFG1(z, l, params):\n",
    "\n",
    "\n",
    "    log_PhiStar = params[0]\n",
    "    Phi_star = 10**log_PhiStar\n",
    "\n",
    "    l_erg = l * E_photon_SFG # erg/s\n",
    "    LFs = np.zeros_like(l)\n",
    "\n",
    "    def Phi_IR(log_LIR): #log_LIR = log_10(L_IR / solar_luminosity) # unitless\n",
    "\n",
    "        # from Table 8 in Gruppioni et al.\n",
    "        # Phi_star = 10**(-2.08) # Mpc^{-3} dex^{-1}\n",
    "        Lstar = 10**(9.46) # Solar luminosity\n",
    "        alpha = 1.00\n",
    "        sigma = 0.50\n",
    "\n",
    "        LIR = 10**log_LIR # solar luminosity\n",
    "\n",
    "        Phi_IR = Phi_star * (LIR / Lstar)**(1 - alpha) * np.exp(-1 / (2 * sigma**2) * (np.log10(1 + LIR / Lstar))**2) # from Gruppioni paper eqn (3)  \t\n",
    "\n",
    "        return Phi_IR\n",
    "\n",
    "    def PDF_log_Lgamma_given_log_LIR(log_LIR, log_Lgamma): #log_LIR = log_10(L_IR / solar_luminosity) # unitless\n",
    "        LIR_solar_luminosity = 10**log_LIR # Solar luminosity\n",
    "        L_IR_erg_second = LIR_solar_luminosity * 3.826e33 # erg/s\n",
    "\n",
    "        a = 1.09\n",
    "        g = 40.8\n",
    "        sigma_SF = 0.202 \n",
    "\n",
    "        mean = g + a * np.log10(L_IR_erg_second / 1e45)\n",
    "        std = sigma_SF\n",
    "\n",
    "        return norm.pdf(log_Lgamma, loc=mean, scale=std)\n",
    "\n",
    "    def integrand(PhiIR_of_logLIRs, log_LIRs, log_Lgamma):\n",
    "        return PhiIR_of_logLIRs * PDF_log_Lgamma_given_log_LIR(log_LIRs, log_Lgamma)\n",
    "\n",
    "    PhiIR_of_logLIRs = Phi_IR(log_LIRs)\n",
    "\n",
    "    for i in range(LFs.shape[0]):\n",
    "        for j in range(LFs.shape[1]):\n",
    "            LFs[i,j] = simpson(integrand(PhiIR_of_logLIRs, log_LIRs, np.log10(l_erg[i,j])), x=log_LIRs)\n",
    "    return 1e-9 / np.log(10) / l * LFs # LF has spatial units of Mpc^{-3}. We need to convert this to kpc^{-3}. Hence the factor of 1e-9\n",
    "\n",
    "\n",
    "def spec_SFG1(energy, params):\n",
    "    Gamma = 2.2\n",
    "    return energy**(-Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZL_mAGN(z, l, params):\n",
    "\n",
    "    log_phi1 = params[1]\n",
    "    phi1 = 10**log_phi1\n",
    "\n",
    "    l_erg = l * E_photon_mAGN # erg/s\n",
    "    LFs = np.zeros_like(l)\n",
    "\n",
    "    def Phi_5G(log_L5G, z): #log_L5G = log_10(L_5GHz / (erg/s)) # unitless\n",
    "        #Output is in Mpc^{-3}\n",
    "\n",
    "        L_5G = 10**log_L5G # erg/s\n",
    "        radio_bandwidth = 4.87e9 # measured in Hz # width of radio band centered around blueshifted frequency of 5GHz \n",
    "        diff_L5G = L_5G / radio_bandwidth * 1e-7 # measured in W/Hz # Converted erg to Joule # luminosity per unit frequency\n",
    "\n",
    "        # Values taken from Table 4 of Yuan 2018 paper. Second row.\n",
    "        p1 = 2.085\n",
    "        p2 = -4.602\n",
    "        z_c = 0.893\n",
    "        k1 = 1.744\n",
    "        e1 = ( (1+z_c)**p1 + (1+z_c)**p2 ) / ( ((1+z_c)/(1+z))**p1 + ((1+z_c)/(1+z))**p2 )\n",
    "        e2 = (1+z)**k1\n",
    "        # phi1 = 10**(-3.749) # Mpc^{-3}\n",
    "        L_star = 10**21.592 # W/Hz\n",
    "        beta = 0.139\n",
    "        gamma = 0.878\n",
    "\n",
    "        # From Yuan 2018 paper equation 21\n",
    "        # Note that this is dN/dV dlog(diff_5G). But this is also equal to dN/dV dlog(L_5G) because the radio bandwidth is fixed.\n",
    "        Phi_5G = e1 * phi1 * ( (diff_L5G / (e2 * L_star))**beta + (diff_L5G / (e2 * L_star))**gamma )**-1\n",
    "\n",
    "        return Phi_5G\n",
    "    \n",
    "\n",
    "    def PDF_log_Lgamma_given_log_L5G(log_L5G, log_Lgamma): #log_L5G = log_10(L_5GHz / (erg/s)) # unitless\n",
    "        L_5GHz = 10**log_L5G # erg/s\n",
    "\n",
    "        b = 0.78\n",
    "        d = 40.78\n",
    "        sigma_mAGN = 0.880\n",
    "\n",
    "        mean = d + b * np.log10(L_5GHz / 1e40)\n",
    "        std = sigma_mAGN\n",
    "\n",
    "        return norm.pdf(log_Lgamma, loc=mean, scale=std)\n",
    "    \n",
    "\n",
    "    def integrand(log_L5G, z, log_Lgamma):\n",
    "        return Phi_5G(log_L5G, z) * PDF_log_Lgamma_given_log_L5G(log_L5G, log_Lgamma)\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(LFs.shape[0]):\n",
    "        for j in range(LFs.shape[1]):\n",
    "            LFs[i,j] = simpson(integrand(log_L5Gs, z[i,j], np.log10(l_erg[i,j])), x=log_L5Gs)\n",
    "\n",
    "\n",
    "    return 1e-9 / np.log(10) / l * LFs # LF has spatial units of Mpc^{-3}. We need to convert this to kpc^{-3}. Hence the factor of 1e-9\n",
    "\n",
    "\n",
    "\n",
    "def spec_mAGN(energy, params):\n",
    "    Gamma = 2.2 #modified sepctrum to match the SFG spectrum\n",
    "    return energy**(-Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_SFG1 = [ZL_SFG1, spec_SFG1]\n",
    "als_mAGN = [ZL_mAGN, spec_mAGN]\n",
    "my_AEGIS.abun_lum_spec = [als_SFG1, als_mAGN]\n",
    "my_AEGIS.source_class_list = ['extragalactic_isotropic_faint_single_spectrum', 'extragalactic_isotropic_faint_single_spectrum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple simulator with the total number of photons as the summary statistic\n",
    "def simulator(params):\n",
    "\n",
    "    input_params = params.numpy()\n",
    "\n",
    "    source_info = my_AEGIS.create_sources(input_params, grains=grains, epsilon=1e-2)\n",
    "    photon_info = my_AEGIS.generate_photons_from_sources(input_params, source_info, grains=grains) \n",
    "    obs_info = {'psf_fits_path': '../../DGRB/FERMI_files/psf_P8R3_ULTRACLEANVETO_V2_PSF.fits', 'edisp_fits_path': '../../DGRB/FERMI_files/edisp_P8R3_ULTRACLEANVETO_V2_PSF.fits', 'event_type': 'PSF3', 'exposure_map': None}\n",
    "    obs_photon_info = my_AEGIS.mock_observe(photon_info, obs_info)\n",
    "    \n",
    "    return obs_photon_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_simulate_for_sbi(proposal, num_simulations=1000, num_workers=32):\n",
    "    \"\"\"\n",
    "    Simulates the model in parallel using joblib.\n",
    "    Each simulation call samples a parameter from the proposal and passes the index to the simulator.\n",
    "    \"\"\"\n",
    "    def run_simulation(i):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"i= {i}\")\n",
    "        # Sample a parameter from the proposal (sbi.utils.BoxUniform has a .sample() method)\n",
    "        theta_i = proposal.sample()\n",
    "        photon_info = simulator(theta_i)\n",
    "        return theta_i, photon_info\n",
    "\n",
    "    # Run simulations in parallel using joblib.\n",
    "    results = Parallel(n_jobs=num_workers, timeout=None)(delayed(run_simulation)(i) for i in range(num_simulations))\n",
    "    theta_list, photon_info_list = zip(*results)\n",
    "\n",
    "    theta_tensor = torch.stack(theta_list, dim=0).to(torch.float32)\n",
    "    \n",
    "    \n",
    "    return theta_tensor, photon_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 10\n",
      "i= 0\n",
      "i= 30\n",
      "i= 20\n",
      "i= 50\n",
      "i= 70\n",
      "i= 40\n",
      "i= 60\n",
      "i= 100\n",
      "i= 90\n",
      "i= 160\n",
      "i= 120\n",
      "i= 130\n",
      "i= 80\n",
      "i= 150\n",
      "i= 170\n",
      "i= 190\n",
      "i= 140\n",
      "i= 110\n",
      "i= 180\n",
      "i= 200\n",
      "i= 210\n",
      "i= 220\n",
      "i= 230\n",
      "i= 240\n",
      "i= 250\n",
      "i= 260\n",
      "i= 270\n",
      "i= 280\n",
      "i= 290\n",
      "i= 300\n",
      "i= 310\n",
      "i= 320\n",
      "i= 330\n",
      "i= 340\n",
      "i= 350\n",
      "i= 360\n",
      "i= 370\n",
      "i= 380\n",
      "i= 390\n",
      "i= 400\n",
      "i= 410\n",
      "i= 420\n",
      "i= 430\n",
      "i= 440\n",
      "i= 450\n",
      "i= 460\n",
      "i= 470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ids29/.conda/envs/sbi_env/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 480\n",
      "i= 490\n",
      "i= 500\n",
      "i= 510\n",
      "i= 520\n",
      "i= 530\n",
      "i= 540\n",
      "i= 550\n",
      "i= 560\n",
      "i= 570\n",
      "i= 580\n",
      "i= 590\n",
      "i= 600\n",
      "i= 610\n",
      "i= 620\n",
      "i= 630\n",
      "i= 640\n",
      "i= 650\n",
      "i= 660\n",
      "i= 670\n",
      "i= 680\n",
      "i= 690\n",
      "i= 700\n",
      "i= 710\n",
      "i= 720\n",
      "i= 730\n",
      "i= 740\n",
      "i= 750\n",
      "i= 760\n",
      "i= 770\n",
      "i= 780\n",
      "i= 790\n",
      "i= 800\n",
      "i= 810\n",
      "i= 820\n",
      "i= 830\n",
      "i= 840\n",
      "i= 850\n",
      "i= 860\n",
      "i= 870\n",
      "i= 880\n",
      "i= 890\n",
      "i= 900\n",
      "i= 910\n",
      "i= 920\n",
      "i= 930\n",
      "i= 940\n",
      "i= 950\n",
      "i= 960\n",
      "i= 970\n",
      "i= 980\n",
      "i= 990\n"
     ]
    }
   ],
   "source": [
    "# Define the prior using sbi.utils.BoxUniform\n",
    "parameter_range = torch.tensor([[-5.0, -6.5],\n",
    "                                [-1.0, -2.5]])\n",
    "\n",
    "prior = utils.BoxUniform(low=parameter_range[0], high=parameter_range[1])\n",
    "\n",
    "theta, train_photon_info_list = manual_simulate_for_sbi(prior,\n",
    "                                   num_simulations=num_simulations,\n",
    "                                   num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'photon_info_list' is a list of dictionaries\n",
    "\n",
    "# Save to file\n",
    "with open('/home/users/ids29/DGRB Scripts/training_photon_info_list_1SFG_1mAGN.pkl', 'wb') as f:\n",
    "    pickle.dump(train_photon_info_list, f)\n",
    "\n",
    "# Save to file\n",
    "torch.save(theta, '/home/users/ids29/DGRB Scripts/thetas_1SFG_1mAGN.pt')\n",
    "torch.save(parameter_range, '/home/users/ids29/DGRB Scripts/parameter_range_1SFG_1mAGN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params_1 = torch.tensor([-2.08, -3.749])\n",
    "test_photon_info_1 = simulator(test_params_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_params_2 = torch.tensor([-4.08, -5.55])\n",
    "test_photon_info_2 = simulator(test_params_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_params_1, r'/home/users/ids29/DGRB Scripts/test_params_1SFG_1mAGN_part1.pt')\n",
    "\n",
    "with open(r'/home/users/ids29/DGRB Scripts/test_photon_info_1SFG_1mAGN_part1.pkl', 'wb') as f:\n",
    "    pickle.dump(test_photon_info_1, f)\n",
    "\n",
    "\n",
    "torch.save(test_params_2, r'/home/users/ids29/DGRB Scripts/test_params_1SFG_1mAGN_part2.pt')\n",
    "\n",
    "with open(r'/home/users/ids29/DGRB Scripts/test_photon_info_1SFG_1mAGN_part2.pkl', 'wb') as f:\n",
    "    pickle.dump(test_photon_info_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m results = Parallel(n_jobs=-\u001b[32m1\u001b[39m)(delayed(simulator)(theta) \u001b[38;5;28;01mfor\u001b[39;00m theta \u001b[38;5;129;01min\u001b[39;00m theta_tensors)\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Extract norm_energy_dependent_hist\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m norm_hists = [res[\u001b[32m1\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mnorm_energy_dependent_hist\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Visualize the 2D histograms\u001b[39;00m\n\u001b[32m     25\u001b[39m fig, axes = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, figsize=(\u001b[32m18\u001b[39m, \u001b[32m10\u001b[39m))\n",
      "\u001b[31mKeyError\u001b[39m: 1"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Define the six θ values\n",
    "theta_values = [\n",
    "    [-5.0, -6.5],\n",
    "    [-5.0, -2.5],\n",
    "    [-1.0, -6.5],\n",
    "    [-1.0, -2.5],\n",
    "    [-2.08, -3.749],\n",
    "    [-4.08, -5.55]\n",
    "]\n",
    "\n",
    "# Convert to tensor\n",
    "theta_tensors = [torch.tensor(theta) for theta in theta_values]\n",
    "\n",
    "# Run simulations in parallel\n",
    "results = Parallel(n_jobs=-1)(delayed(simulator)(theta) for theta in theta_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"simulator_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aegis\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import torch\n",
    "import pickle as pk\n",
    "from astropy import units as u\n",
    "from astropy import constants as c\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "import os\n",
    "import sys\n",
    "from sbi.inference import SNLE, SNPE#, prepare_for_sbi, simulate_for_sbi\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "# from sbi.inference.base import infer\n",
    "from getdist import plots, MCSamples\n",
    "import pickle\n",
    "from scipy.stats import norm\n",
    "from scipy.integrate import quad, simpson\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grains=1000\n",
    "num_simulations = 1000\n",
    "num_workers = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_range = [[], []]\n",
    "abundance_luminosity_and_spectrum_list = []\n",
    "source_class_list = []\n",
    "parameter_names = []\n",
    "energy_range = [2000, 100000] #MeV\n",
    "energy_range_gen = [energy_range[0]*0.5, energy_range[1]*1.5]\n",
    "max_radius = 8.5 + 20*2 #kpc\n",
    "exposure = 2000*10*0.2 #cm^2 yr\n",
    "flux_cut = 1e-9 #photons/cm^2/s\n",
    "angular_cut = np.pi #10*u.deg.to('rad') #degrees\n",
    "angular_cut_gen = angular_cut*1.5\n",
    "lat_cut = 0 #2*u.deg.to('rad') #degrees\n",
    "lat_cut_gen = lat_cut*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!WARNING!!! Some high energy photons that could be redshifted into the final energy range may not be generated. It is recommended to increase the maximum generating energy\n"
     ]
    }
   ],
   "source": [
    "my_cosmology = 'Planck18'\n",
    "z_range = [0, 14]\n",
    "luminosity_range = 10.0**np.array([37, 50]) # Minimum value set by considering Andromeda distance using Fermi as benchmark and receiving 0.1 photon at detector side\n",
    "my_AEGIS = aegis.aegis(abundance_luminosity_and_spectrum_list, source_class_list, parameter_range, energy_range, luminosity_range, max_radius, exposure, angular_cut, lat_cut, flux_cut, cosmology = my_cosmology, z_range = z_range, verbose = False)\n",
    "my_AEGIS.angular_cut_gen, my_AEGIS.lat_cut_gen, my_AEGIS.Emin_gen, my_AEGIS.Emax_gen = angular_cut_gen, lat_cut_gen, energy_range_gen[0], energy_range_gen[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gamma_SFG = 2.2\n",
    "gamma_energy_bounds = np.array([0.1, 1000])  # in GeV\n",
    "E_photon_GeV_SFG = ((-Gamma_SFG + 1) / (-Gamma_SFG + 2) *\n",
    "                (gamma_energy_bounds[1]**(-Gamma_SFG + 2) - gamma_energy_bounds[0]**(-Gamma_SFG + 2)) /\n",
    "                (gamma_energy_bounds[1]**(-Gamma_SFG + 1) - gamma_energy_bounds[0]**(-Gamma_SFG + 1)))\n",
    "E_photon_SFG = E_photon_GeV_SFG * 0.00160218  # erg\n",
    "\n",
    "Gamma_mAGN = 2.25\n",
    "gamma_energy_bounds = np.array([0.1, 1000])  # in GeV\n",
    "E_photon_GeV_mAGN = ((-Gamma_mAGN + 1) / (-Gamma_mAGN + 2) *\n",
    "                (gamma_energy_bounds[1]**(-Gamma_mAGN + 2) - gamma_energy_bounds[0]**(-Gamma_mAGN + 2)) /\n",
    "                (gamma_energy_bounds[1]**(-Gamma_mAGN + 1) - gamma_energy_bounds[0]**(-Gamma_mAGN + 1)))\n",
    "E_photon_mAGN = E_photon_GeV_mAGN * 0.00160218  # erg\n",
    "\n",
    "res = int(1e4)\n",
    "log_LIRs = np.linspace(-5, 25, res)\n",
    "log_L5Gs = np.linspace(20, 55, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZL_SFG1(z, l, params):\n",
    "\n",
    "\n",
    "    log_PhiStar = params[0]\n",
    "    Phi_star = 10**log_PhiStar\n",
    "\n",
    "    l_erg = l * E_photon_SFG # erg/s\n",
    "    LFs = np.zeros_like(l)\n",
    "\n",
    "    def Phi_IR(log_LIR): #log_LIR = log_10(L_IR / solar_luminosity) # unitless\n",
    "\n",
    "        # from Table 8 in Gruppioni et al.\n",
    "        # Phi_star = 10**(-2.08) # Mpc^{-3} dex^{-1}\n",
    "        Lstar = 10**(9.46) # Solar luminosity\n",
    "        alpha = 1.00\n",
    "        sigma = 0.50\n",
    "\n",
    "        LIR = 10**log_LIR # solar luminosity\n",
    "\n",
    "        Phi_IR = Phi_star * (LIR / Lstar)**(1 - alpha) * np.exp(-1 / (2 * sigma**2) * (np.log10(1 + LIR / Lstar))**2) # from Gruppioni paper eqn (3)  \t\n",
    "\n",
    "        return Phi_IR\n",
    "\n",
    "    def PDF_log_Lgamma_given_log_LIR(log_LIR, log_Lgamma): #log_LIR = log_10(L_IR / solar_luminosity) # unitless\n",
    "        LIR_solar_luminosity = 10**log_LIR # Solar luminosity\n",
    "        L_IR_erg_second = LIR_solar_luminosity * 3.826e33 # erg/s\n",
    "\n",
    "        a = 1.09\n",
    "        g = 40.8\n",
    "        sigma_SF = 0.202 \n",
    "\n",
    "        mean = g + a * np.log10(L_IR_erg_second / 1e45)\n",
    "        std = sigma_SF\n",
    "\n",
    "        return norm.pdf(log_Lgamma, loc=mean, scale=std)\n",
    "\n",
    "    def integrand(PhiIR_of_logLIRs, log_LIRs, log_Lgamma):\n",
    "        return PhiIR_of_logLIRs * PDF_log_Lgamma_given_log_LIR(log_LIRs, log_Lgamma)\n",
    "\n",
    "    PhiIR_of_logLIRs = Phi_IR(log_LIRs)\n",
    "\n",
    "    for i in range(LFs.shape[0]):\n",
    "        for j in range(LFs.shape[1]):\n",
    "            LFs[i,j] = simpson(integrand(PhiIR_of_logLIRs, log_LIRs, np.log10(l_erg[i,j])), x=log_LIRs)\n",
    "    return 1e-9 / np.log(10) / l * LFs # LF has spatial units of Mpc^{-3}. We need to convert this to kpc^{-3}. Hence the factor of 1e-9\n",
    "\n",
    "\n",
    "def spec_SFG1(energy, params):\n",
    "    Gamma = 2.2\n",
    "    return energy**(-Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZL_SFG2(z, l, params):\n",
    "\n",
    "\n",
    "    log_PhiStar = params[1]\n",
    "    Phi_star = 10**log_PhiStar\n",
    "\n",
    "    l_erg = l * E_photon_SFG # erg/s\n",
    "    LFs = np.zeros_like(l)\n",
    "\n",
    "    def Phi_IR(log_LIR): #log_LIR = log_10(L_IR / solar_luminosity) # unitless\n",
    "\n",
    "        # from Table 8 in Gruppioni et al.\n",
    "        # Phi_star = 10**(−4.74) # Mpc^{-3} dex^{-1}\n",
    "        Lstar = 10**(11.02) # Solar luminosity\n",
    "        alpha = 1.00\n",
    "        sigma = 0.35\n",
    "\n",
    "        LIR = 10**log_LIR # solar luminosity\n",
    "\n",
    "        Phi_IR = Phi_star * (LIR / Lstar)**(1 - alpha) * np.exp(-1 / (2 * sigma**2) * (np.log10(1 + LIR / Lstar))**2) # from Gruppioni paper eqn (3)  \t\n",
    "\n",
    "        return Phi_IR\n",
    "\n",
    "    def PDF_log_Lgamma_given_log_LIR(log_LIR, log_Lgamma): #log_LIR = log_10(L_IR / solar_luminosity) # unitless\n",
    "        LIR_solar_luminosity = 10**log_LIR # Solar luminosity\n",
    "        L_IR_erg_second = LIR_solar_luminosity * 3.826e33 # erg/s\n",
    "\n",
    "        a = 1.09\n",
    "        g = 40.8\n",
    "        sigma_SF = 0.202 \n",
    "\n",
    "        mean = g + a * np.log10(L_IR_erg_second / 1e45)\n",
    "        std = sigma_SF\n",
    "\n",
    "        return norm.pdf(log_Lgamma, loc=mean, scale=std)\n",
    "\n",
    "    def integrand(PhiIR_of_logLIRs, log_LIRs, log_Lgamma):\n",
    "        return PhiIR_of_logLIRs * PDF_log_Lgamma_given_log_LIR(log_LIRs, log_Lgamma)\n",
    "\n",
    "    PhiIR_of_logLIRs = Phi_IR(log_LIRs)\n",
    "\n",
    "    for i in range(LFs.shape[0]):\n",
    "        for j in range(LFs.shape[1]):\n",
    "            LFs[i,j] = simpson(integrand(PhiIR_of_logLIRs, log_LIRs, np.log10(l_erg[i,j])), x=log_LIRs)\n",
    "    return 1e-9 / np.log(10) / l * LFs # LF has spatial units of Mpc^{-3}. We need to convert this to kpc^{-3}. Hence the factor of 1e-9\n",
    "\n",
    "\n",
    "def spec_SFG2(energy, params):\n",
    "    Gamma = 2.2\n",
    "    return energy**(-Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZL_SFG3(z, l, params):\n",
    "\n",
    "\n",
    "    log_PhiStar = params[2]\n",
    "    Phi_star = 10**log_PhiStar\n",
    "\n",
    "    l_erg = l * E_photon_SFG # erg/s\n",
    "    LFs = np.zeros_like(l)\n",
    "\n",
    "    def Phi_IR(log_LIR): #log_LIR = log_10(L_IR / solar_luminosity) # unitless\n",
    "\n",
    "        # from Table 8 in Gruppioni et al.\n",
    "        # Phi_star = 10**(−3.25) # Mpc^{-3} dex^{-1}\n",
    "        Lstar = 10**(10.57) # Solar luminosity\n",
    "        alpha = 1.2\n",
    "        sigma = 0.4\n",
    "\n",
    "        LIR = 10**log_LIR # solar luminosity\n",
    "\n",
    "        Phi_IR = Phi_star * (LIR / Lstar)**(1 - alpha) * np.exp(-1 / (2 * sigma**2) * (np.log10(1 + LIR / Lstar))**2) # from Gruppioni paper eqn (3)  \t\n",
    "\n",
    "        return Phi_IR\n",
    "\n",
    "    def PDF_log_Lgamma_given_log_LIR(log_LIR, log_Lgamma): #log_LIR = log_10(L_IR / solar_luminosity) # unitless\n",
    "        LIR_solar_luminosity = 10**log_LIR # Solar luminosity\n",
    "        L_IR_erg_second = LIR_solar_luminosity * 3.826e33 # erg/s\n",
    "\n",
    "        a = 1.09\n",
    "        g = 40.8\n",
    "        sigma_SF = 0.202 \n",
    "\n",
    "        mean = g + a * np.log10(L_IR_erg_second / 1e45)\n",
    "        std = sigma_SF\n",
    "\n",
    "        return norm.pdf(log_Lgamma, loc=mean, scale=std)\n",
    "\n",
    "    def integrand(PhiIR_of_logLIRs, log_LIRs, log_Lgamma):\n",
    "        return PhiIR_of_logLIRs * PDF_log_Lgamma_given_log_LIR(log_LIRs, log_Lgamma)\n",
    "\n",
    "    PhiIR_of_logLIRs = Phi_IR(log_LIRs)\n",
    "\n",
    "    for i in range(LFs.shape[0]):\n",
    "        for j in range(LFs.shape[1]):\n",
    "            LFs[i,j] = simpson(integrand(PhiIR_of_logLIRs, log_LIRs, np.log10(l_erg[i,j])), x=log_LIRs)\n",
    "    return 1e-9 / np.log(10) / l * LFs # LF has spatial units of Mpc^{-3}. We need to convert this to kpc^{-3}. Hence the factor of 1e-9\n",
    "\n",
    "\n",
    "def spec_SFG3(energy, params):\n",
    "    Gamma = 2.2\n",
    "    return energy**(-Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZL_mAGN(z, l, params):\n",
    "\n",
    "    log_phi1 = params[3]\n",
    "    phi1 = 10**log_phi1\n",
    "\n",
    "    l_erg = l * E_photon_mAGN # erg/s\n",
    "    LFs = np.zeros_like(l)\n",
    "\n",
    "    def Phi_5G(log_L5G, z): #log_L5G = log_10(L_5GHz / (erg/s)) # unitless\n",
    "        #Output is in Mpc^{-3}\n",
    "\n",
    "        L_5G = 10**log_L5G # erg/s\n",
    "        radio_bandwidth = 4.87e9 # measured in Hz # width of radio band centered around blueshifted frequency of 5GHz \n",
    "        diff_L5G = L_5G / radio_bandwidth * 1e-7 # measured in W/Hz # Converted erg to Joule # luminosity per unit frequency\n",
    "\n",
    "        # Values taken from Table 4 of Yuan 2018 paper. Second row.\n",
    "        p1 = 2.085\n",
    "        p2 = -4.602\n",
    "        z_c = 0.893\n",
    "        k1 = 1.744\n",
    "        e1 = ( (1+z_c)**p1 + (1+z_c)**p2 ) / ( ((1+z_c)/(1+z))**p1 + ((1+z_c)/(1+z))**p2 )\n",
    "        e2 = (1+z)**k1\n",
    "        # phi1 = 10**(-3.749) # Mpc^{-3}\n",
    "        L_star = 10**21.592 # W/Hz\n",
    "        beta = 0.139\n",
    "        gamma = 0.878\n",
    "\n",
    "        # From Yuan 2018 paper equation 21\n",
    "        # Note that this is dN/dV dlog(diff_5G). But this is also equal to dN/dV dlog(L_5G) because the radio bandwidth is fixed.\n",
    "        Phi_5G = e1 * phi1 * ( (diff_L5G / (e2 * L_star))**beta + (diff_L5G / (e2 * L_star))**gamma )**-1\n",
    "\n",
    "        return Phi_5G\n",
    "    \n",
    "\n",
    "    def PDF_log_Lgamma_given_log_L5G(log_L5G, log_Lgamma): #log_L5G = log_10(L_5GHz / (erg/s)) # unitless\n",
    "        L_5GHz = 10**log_L5G # erg/s\n",
    "\n",
    "        b = 0.78\n",
    "        d = 40.78\n",
    "        sigma_mAGN = 0.880\n",
    "\n",
    "        mean = d + b * np.log10(L_5GHz / 1e40)\n",
    "        std = sigma_mAGN\n",
    "\n",
    "        return norm.pdf(log_Lgamma, loc=mean, scale=std)\n",
    "    \n",
    "\n",
    "    def integrand(log_L5G, z, log_Lgamma):\n",
    "        return Phi_5G(log_L5G, z) * PDF_log_Lgamma_given_log_L5G(log_L5G, log_Lgamma)\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(LFs.shape[0]):\n",
    "        for j in range(LFs.shape[1]):\n",
    "            LFs[i,j] = simpson(integrand(log_L5Gs, z[i,j], np.log10(l_erg[i,j])), x=log_L5Gs)\n",
    "\n",
    "\n",
    "    return 1e-9 / np.log(10) / l * LFs # LF has spatial units of Mpc^{-3}. We need to convert this to kpc^{-3}. Hence the factor of 1e-9\n",
    "\n",
    "\n",
    "\n",
    "def spec_mAGN(energy, params):\n",
    "    Gamma = 2.25\n",
    "    return energy**(-Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_SFG1 = [ZL_SFG1, spec_SFG1]\n",
    "als_SFG2 = [ZL_SFG2, spec_SFG2]\n",
    "als_SFG3 = [ZL_SFG3, spec_SFG3]\n",
    "als_mAGN = [ZL_mAGN, spec_mAGN]\n",
    "my_AEGIS.abun_lum_spec = [als_SFG1, als_SFG2, als_SFG3, als_mAGN]\n",
    "my_AEGIS.source_class_list = ['extragalactic_isotropic_faint_single_spectrum', 'extragalactic_isotropic_faint_single_spectrum', 'extragalactic_isotropic_faint_single_spectrum', 'extragalactic_isotropic_faint_single_spectrum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_moments(energies):\n",
    "#     \"\"\"Compute the mean and variance of the energies.\"\"\"\n",
    "#     mean_E = np.mean(energies)\n",
    "#     var_E = np.var(energies)\n",
    "#     return mean_E, var_E\n",
    "\n",
    "# def compute_quantiles(energies, quantiles=[10, 25, 50, 75, 90]):\n",
    "#     \"\"\"\n",
    "#     Compute the specified quantiles (in percent).\n",
    "#     For example, the 25th quantile is the energy such that 25% of the data lies below it.\n",
    "#     Returns a dictionary mapping percentiles to values.\n",
    "#     \"\"\"\n",
    "#     q_values = np.percentile(energies, quantiles)\n",
    "#     return dict(zip(quantiles, q_values))\n",
    "\n",
    "\n",
    "# def compute_energy_only_histogram(energies, num_bins, energy_range=energy_range):\n",
    "#     \"\"\"\n",
    "#     Compute a 1D histogram of energies using logarithmic binning.\n",
    "#     Returns the histogram counts and the bin edges.\n",
    "#     \"\"\"\n",
    "#     bins = np.geomspace(energy_range[0], energy_range[1], num_bins + 1)\n",
    "#     hist, _ = np.histogram(energies, bins=bins)\n",
    "#     return hist\n",
    "\n",
    "# def effective_spectral_index(energies, E_lower, min_count=6):\n",
    "#     \"\"\"\n",
    "#     Compute effective spectral index via MLE, or return -1 if not enough photons.\n",
    "#     \"\"\"\n",
    "#     energies = np.array(energies)\n",
    "#     n = len(energies)\n",
    "#     if n < min_count:\n",
    "#         return -100.0  # Sentinel value indicating unreliable or undefined\n",
    "#     sum_logs = np.sum(np.log(energies / E_lower))\n",
    "#     gamma_hat = 1 + n / sum_logs\n",
    "#     return gamma_hat\n",
    "\n",
    "# def compute_global_effective_spectral_index(energies, E_lower=energy_range[0]):\n",
    "#     \"\"\"\n",
    "#     Compute the effective spectral index using all the photon energies.\n",
    "#     This value can be used as a fallback when a particular energy bin is empty.\n",
    "#     \"\"\"\n",
    "#     return effective_spectral_index(energies, E_lower)\n",
    "\n",
    "# def compute_binned_effective_spectral_indices(energies, num_bins, energy_range=energy_range):\n",
    "#     \"\"\"\n",
    "#     Divide the energy range into logarithmic bins and compute the effective spectral index in each bin.\n",
    "#     For bins that have no photons, the global effective spectral index (computed from all energies)\n",
    "#     is used as the fallback.\n",
    "    \n",
    "#     Returns a 1D array containing the spectral index for each bin.\n",
    "#     \"\"\"\n",
    "#     # Create logarithmically spaced bins.\n",
    "#     bins = np.geomspace(energy_range[0], energy_range[1], num_bins + 1)\n",
    "    \n",
    "#     # Compute the global effective spectral index from all the energies.\n",
    "#     global_gamma = compute_global_effective_spectral_index(energies, E_lower=bins[0])\n",
    "    \n",
    "#     gamma_bins = []\n",
    "#     for i in range(len(bins) - 1):\n",
    "#         # Select energies within current bin: lower inclusive, upper exclusive.\n",
    "#         mask = (energies >= bins[i]) & (energies < bins[i+1])\n",
    "#         energies_bin = energies[mask]\n",
    "        \n",
    "#         # Compute the effective spectral index for this bin.\n",
    "#         gamma_bin = effective_spectral_index(energies_bin, E_lower=bins[i])\n",
    "\n",
    "#         gamma_bins.append(gamma_bin)\n",
    "    \n",
    "#     return np.array(gamma_bins), global_gamma\n",
    "\n",
    "# def compute_summary_statistics(energies, energy_dependent_hist, N_Ebins):\n",
    "#     \"\"\"\n",
    "#     Given an array of photon energies (all between 2 and 100 GeV), compute a set of summary statistics:\n",
    "#       1. Mean energy.\n",
    "#       2. Variance of energy.\n",
    "#       3. Quantiles: 10%, 25%, 50%, 75%, and 90%.\n",
    "#       NOT DOING: 4. The fraction of photons with energy above E_cross (where E_cross is the crossing point\n",
    "#          for the two normalized PDFs of the Gamma = 2.2 and Gamma = 2.25 spectra).\n",
    "#       5. Effective spectral index estimated from the data.\n",
    "      \n",
    "#     Returns the statistics in a dictionary and also a flattened torch tensor.\n",
    "#     \"\"\"\n",
    "#     # 1. Mean and variance\n",
    "#     mean_E, var_E = compute_moments(energies)\n",
    "    \n",
    "#     # 2. Quantiles\n",
    "#     quant_dict = compute_quantiles(energies)  # This returns a dict like {10: val, 25: val, ...}\n",
    "    \n",
    "#     # 4. Effective spectral index estimation\n",
    "#     # gamma_eff = effective_spectral_index(energies, E_lower=energy_range[0])\n",
    "\n",
    "#     energy_only_hist = compute_energy_only_histogram(energies, num_bins=N_Ebins, energy_range=energy_range)\n",
    "\n",
    "#     binned_gamma, global_gamma = compute_binned_effective_spectral_indices(energies, num_bins=N_Ebins, energy_range=energy_range)\n",
    "    \n",
    "    \n",
    "#     # If you want to pass the summary statistic to sbi, it is best to use a fixed-size vector (e.g., a torch tensor).\n",
    "#     # For example, arrange the stats in a consistent order:\n",
    "#     scalars  = np.array([\n",
    "#         energies.size, # total number of photons\n",
    "#         mean_E,\n",
    "#         var_E,\n",
    "#         quant_dict[10],\n",
    "#         quant_dict[25],\n",
    "#         quant_dict[50],\n",
    "#         quant_dict[75],\n",
    "#         quant_dict[90],\n",
    "#         global_gamma\n",
    "#     ], dtype=np.float32)\n",
    "    \n",
    "#     flat_energy_dependent_hist = np.asarray(energy_dependent_hist, dtype=np.float32).flatten()\n",
    "#     summary_vector = np.concatenate([flat_energy_dependent_hist, energy_only_hist, binned_gamma, scalars]) # energies.size is the total number of photons\n",
    "\n",
    "#     # Convert to a torch tensor if needed by sbi.\n",
    "#     summary_tensor = torch.tensor(summary_vector)\n",
    "    \n",
    "#     return summary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple simulator with the total number of photons as the summary statistic\n",
    "def simulator(params):\n",
    "\n",
    "    input_params = params.numpy()\n",
    "\n",
    "    source_info = my_AEGIS.create_sources(input_params, grains=grains, epsilon=1e-2)\n",
    "    photon_info = my_AEGIS.generate_photons_from_sources(input_params, source_info, grains=grains) \n",
    "\n",
    "    # N_side = 2**6\n",
    "    # #parameters for the summary statistic\n",
    "    \n",
    "    # center_mask = 10 #deg \n",
    "    # lat_mask = 5 #deg \n",
    "    # N_Ebins = 20\n",
    "    # Ebinspace = 'log'#'linear'\n",
    "    # N_countbins = 10\n",
    "    # countbinspace = 'custom'#'linear'\n",
    "    # if N_side == 2**6:\n",
    "    #     mincount, maxcount = 0, 150\n",
    "    # elif N_side == 2**3:\n",
    "    #     mincount, maxcount = 0, 5500\n",
    "    # N_pix = 12*N_side**2\n",
    "    # pix_i = np.linspace(0, N_pix-1, N_pix, dtype = 'int')\n",
    "    # roi_pix_i = np.where(np.logical_and(hp.rotator.angdist(np.array([np.pi/2, 0]), hp.pix2ang(N_side, pix_i)) >= center_mask*u.deg.to('rad'), np.abs(np.pi/2 - hp.pix2ang(N_side, pix_i)[0]) >= lat_mask*u.deg.to('rad')))[0]\n",
    "\n",
    "    # roi_map = my_AEGIS.get_roi_map_summary(photon_info = photon_info, N_side = N_side, N_Ebins = N_Ebins, Ebinspace = Ebinspace, roi_pix_i = roi_pix_i)\n",
    "    # energy_dependent_hist = my_AEGIS.get_counts_histogram_from_roi_map(roi_map, mincount = mincount, maxcount = maxcount, N_countbins = N_countbins, countbinspace = countbinspace)\n",
    "\n",
    "    # photon_pixels = hp.ang2pix(N_side, photon_info['angles'][:, 0], photon_info['angles'][:, 1])\n",
    "    # roi_mask = np.isin(photon_pixels, roi_pix_i)\n",
    "    # energies_in_roi = photon_info['energies'][roi_mask]\n",
    "\n",
    "\n",
    "    # stats_tensor = compute_summary_statistics(energies_in_roi, energy_dependent_hist, N_Ebins = N_Ebins)\n",
    "    \n",
    "    return photon_info #stats_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_simulate_for_sbi(proposal, num_simulations=1000, num_workers=32):\n",
    "    \"\"\"\n",
    "    Simulates the model in parallel using joblib.\n",
    "    Each simulation call samples a parameter from the proposal and passes the index to the simulator.\n",
    "    \"\"\"\n",
    "    def run_simulation(i):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"i= {i}\")\n",
    "        # Sample a parameter from the proposal (sbi.utils.BoxUniform has a .sample() method)\n",
    "        theta_i = proposal.sample()\n",
    "        photon_info = simulator(theta_i)\n",
    "        return theta_i, photon_info\n",
    "\n",
    "    # Run simulations in parallel using joblib.\n",
    "    results = Parallel(n_jobs=num_workers, timeout=None)(delayed(run_simulation)(i) for i in range(num_simulations))\n",
    "    theta_list, photon_info_list = zip(*results)\n",
    "\n",
    "    theta_tensor = torch.stack(theta_list, dim=0).to(torch.float32)\n",
    "    \n",
    "    \n",
    "    return theta_tensor, photon_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 20\n",
      "i= 90\n",
      "i= 50\n",
      "i= 160\n",
      "i= 110\n",
      "i= 40\n",
      "i= 30\n",
      "i= 130\n",
      "i= 10\n",
      "i= 100\n",
      "i= 150\n",
      "i= 80\n",
      "i= 70\n",
      "i= 60\n",
      "i= 190\n",
      "i= 180\n",
      "i= 120\n",
      "i= 0\n",
      "i= 170\n",
      "i= 140\n",
      "i= 200\n",
      "i= 210\n",
      "i= 220\n",
      "i= 230\n",
      "i= 240\n",
      "i= 250\n",
      "i= 260\n",
      "i= 270\n",
      "i= 280\n",
      "i= 290\n",
      "i= 300\n",
      "i= 310\n",
      "i= 320\n",
      "i= 330\n",
      "i= 340\n",
      "i= 350\n",
      "i= 360\n",
      "i= 370\n",
      "i= 380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/phys/Linux/anaconda3.9/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 390\n",
      "i= 400\n",
      "i= 410\n",
      "i= 420\n",
      "i= 430\n",
      "i= 440\n",
      "i= 450\n",
      "i= 460\n",
      "i= 470\n",
      "i= 480\n",
      "i= 490\n",
      "i= 500\n",
      "i= 510\n",
      "i= 520\n",
      "i= 530\n",
      "i= 540\n",
      "i= 550\n",
      "i= 560\n",
      "i= 570\n",
      "i= 580\n",
      "i= 590\n",
      "i= 600\n",
      "i= 610\n",
      "i= 620\n",
      "i= 630\n",
      "i= 640\n",
      "i= 650\n",
      "i= 660\n",
      "i= 670\n",
      "i= 680\n",
      "i= 690\n",
      "i= 700\n",
      "i= 710\n",
      "i= 720\n",
      "i= 730\n",
      "i= 740\n",
      "i= 750\n",
      "i= 760\n",
      "i= 770\n",
      "i= 780\n",
      "i= 790\n",
      "i= 800\n",
      "i= 810\n",
      "i= 820\n",
      "i= 830\n",
      "i= 840\n",
      "i= 850\n",
      "i= 860\n",
      "i= 870\n",
      "i= 880\n",
      "i= 890\n",
      "i= 900\n",
      "i= 910\n",
      "i= 920\n",
      "i= 930\n",
      "i= 940\n",
      "i= 950\n",
      "i= 960\n",
      "i= 970\n",
      "i= 980\n",
      "i= 990\n"
     ]
    }
   ],
   "source": [
    "# Define the prior using sbi.utils.BoxUniform\n",
    "parameter_range = torch.tensor([[-5.0, -7.5 ,-6.5, -6.5],\n",
    "                                [-1.0, -3.5, -2.5, -2.5]])\n",
    "\n",
    "prior = utils.BoxUniform(low=parameter_range[0], high=parameter_range[1])\n",
    "\n",
    "theta, photon_info_list = manual_simulate_for_sbi(prior,\n",
    "                                   num_simulations=num_simulations,\n",
    "                                   num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'photon_info_list' is a list of dictionaries\n",
    "\n",
    "# Save to file\n",
    "with open('/home/users/ids29/DGRB/photon_info_list.pkl', 'wb') as f:\n",
    "    pickle.dump(photon_info_list, f)\n",
    "\n",
    "# Save to file\n",
    "torch.save(theta, '/home/users/ids29/DGRB/thetas.pt')\n",
    "torch.save(parameter_range, '/home/users/ids29/DGRB/parameter_range.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_params = torch.tensor([-2.08, -4.74, -3.25, -3.749])\n",
    "obs_photon_info = simulator(input_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(input_params, r'/home/users/ids29/DGRB/input_params.pt')\n",
    "\n",
    "with open(r'/home/users/ids29/DGRB/obs_photon_info.pkl', 'wb') as f:\n",
    "    pickle.dump(obs_photon_info, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test another observation data where the SFG normalization parameters are two orders of magnitude lesser than above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_params_test = torch.tensor([-1.5, -4.0, -3.0, -3.749])\n",
    "obs_photon_info_test = simulator(input_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(input_params_test, r'/home/users/ids29/DGRB/input_params_test.pt')\n",
    "\n",
    "with open(r'/home/users/ids29/DGRB/obs_photon_info_test.pkl', 'wb') as f:\n",
    "    pickle.dump(obs_photon_info_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
